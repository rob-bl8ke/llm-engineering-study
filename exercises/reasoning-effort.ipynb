{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73b7b20",
   "metadata": {},
   "source": [
    "# Reasoning Effort\n",
    "\n",
    "Reasoning effort can be \"minimal\", \"low\", \"medium\", or \"high\". Notice how the LLM responds given the different reasoning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8abb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Load keys\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "# Connect to OpenAI client library\n",
    "# A thin wrapper around calls to HTTP endpoints\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "# For Gemini, DeepSeek and Groq, we can use the OpenAI python client\n",
    "# Because Google and DeepSeek have endpoints compatible with OpenAI\n",
    "# And OpenAI allows you to change the base_url\n",
    "\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d8acc",
   "metadata": {},
   "source": [
    "Reasoning effort can be \"minimal\", \"low\", \"medium\", or \"high\". Notice how the LLM responds given the different reasoning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d84d9b",
   "metadata": {},
   "source": [
    "### Puzzle: Toss 2 coins\n",
    "\n",
    "- `gpt-5-nano` is currently the smallest model. Ask it to solve the puzzle below using the `reasoning_effort` of \"minimal\". It'll probably give you the wrong answer or 1/2 which is incorrect.\n",
    "- Dial up the reasoning on the same mode and ask it the same question. If it answers 2/3 it is correct. So the higher the reasoning effort, the more chance you have of getting the LLM to answer correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_puzzle = [\n",
    "    {\"role\": \"user\", \"content\": \n",
    "        \"You toss 2 coins. One of them is heads. What's the probability the other is tails? Answer with the probability only.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve with minimal reasoning effort (if it answers 1/2 it's incorrect)\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages=easy_puzzle, reasoning_effort=\"minimal\")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages=easy_puzzle, reasoning_effort=\"low\")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b7879a",
   "metadata": {},
   "source": [
    "### Puzzle: Worm gnawing through books\n",
    "\n",
    "__On a bookshelf, two volumes of Pushkin stand side by side: the first and the second. The pages of each volume together have a thickness of 2 cm, and each cover is 2 mm thick. A worm gnawed (perpendicular to the pages) from the first page of the first volume to the last page of the second volume. What distance did it gnaw through?__\n",
    "\n",
    "This is a harder puzzle, and we'll test out some of the best models on the planet against it. This is a problem that a lot of kids somehow get right but adults and teachers often get it wrong because kids can visualize this stuff better (have a young imagination). If you actually physically go put the books on the bookshelf, you'll see for yourself.\n",
    "\n",
    "The correct answer is: *(Go have a look for yourself)*\n",
    "\n",
    "__The first page of the first volume is closest to the second volume. It's not where you think it is. The first page of the first volume is closest to the second volume, and the last page of the second volume is closest to the first volume. The worm only need to gnaw through the covers in the middle which is 4 mm.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9898f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard = \"\"\"\n",
    "On a bookshelf, two volumes of Pushkin stand side by side: the first and the second.\n",
    "The pages of each volume together have a thickness of 2 cm, and each cover is 2 mm thick.\n",
    "A worm gnawed (perpendicular to the pages) from the first page of the first volume to the last page of the second volume.\n",
    "What distance did it gnaw through?\n",
    "\"\"\"\n",
    "hard_puzzle = [\n",
    "    {\"role\": \"user\", \"content\": hard}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc79b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets it wrong\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages=hard_puzzle, reasoning_effort=\"minimal\")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9446a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets it right... 4 mm\n",
    "response = openai.chat.completions.create(model=\"gpt-5\", messages=hard_puzzle)\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dee944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets it wrong\n",
    "response = anthropic.chat.completions.create(model=\"claude-sonnet-4-5-20250929\", messages=hard_puzzle)\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512df6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets it right \n",
    "response = gemini.chat.completions.create(model=\"gemini-2.5-pro\", messages=hard_puzzle)\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa7b37",
   "metadata": {},
   "source": [
    "## Puzzle: Contestants in a Game Show (Share or Steal)\n",
    "\n",
    "You and a partner are contestants on a game show. You're each taken to separate rooms and given a choice:\n",
    "- Cooperate: Choose \"Share\" — if both of you choose this, you each win $1,000.\n",
    "- Defect: Choose \"Steal\" — if one steals and the other shares, the stealer gets $2,000 and the sharer gets nothing.\n",
    "\n",
    "If both steal, you both get nothing. Do you choose to Steal or Share? Pick one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefdc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilemma_prompt = \"\"\"\n",
    "You and a partner are contestants on a game show. You're each taken to separate rooms and given a choice:\n",
    "Cooperate: Choose \"Share\" — if both of you choose this, you each win $1,000.\n",
    "Defect: Choose \"Steal\" — if one steals and the other shares, the stealer gets $2,000 and the sharer gets nothing.\n",
    "If both steal, you both get nothing.\n",
    "Do you choose to Steal or Share? Pick one.\n",
    "\"\"\"\n",
    "\n",
    "dilemma = [\n",
    "    {\"role\": \"user\", \"content\": dilemma_prompt},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50198aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = anthropic.chat.completions.create(model=\"claude-sonnet-4-5-20250929\", messages=dilemma)\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
